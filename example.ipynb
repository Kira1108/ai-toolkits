{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef24707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_toolkits.structured.extractor import create_object_openai\n",
    "from pydantic import BaseModel, Field\n",
    "from ai_toolkits.llms import create_sync_client\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str = Field(..., description=\"The person's full name\")\n",
    "    age: int = Field(..., description=\"The person's age in years\")\n",
    "    email: str = Field(..., description=\"The person's email address\")\n",
    "\n",
    "obj = create_object_openai(\n",
    "    output_cls=Person, \n",
    "    prompt=\"I saw a girl on the street, I asked her name, she said her name is Tendy Alice, she is 30 years old, her email is alice@example.com\", \n",
    "    client=create_sync_client()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71f7ba48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='Tendy Alice', age=30, email='alice@example.com')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af0d7e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiplying 1234 and 4567\n",
      "The result of \\(1234 \\times 4567\\) is \\(5635678\\).\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "from ai_toolkits.llms import LlamaIndeAzureOpenAI\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Define a simple calculator tool\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Useful for multiplying two numbers.\"\"\"\n",
    "    print(f\"Multiplying {a} and {b}\")\n",
    "    return a * b\n",
    "\n",
    "\n",
    "# Create an agent workflow with our calculator tool\n",
    "agent = FunctionAgent(\n",
    "    tools=[multiply],\n",
    "    llm=LlamaIndeAzureOpenAI(engine=\"gpt-4o\", model=\"gpt-4o\", temperature=0),\n",
    "    system_prompt=\"You are a helpful assistant that can multiply two numbers.\",\n",
    ")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # Run the agent\n",
    "    response = await agent.run(\"What is 1234 * 4567?, Be sure to use tools when doing math.\")\n",
    "    print(str(response))\n",
    "\n",
    "\n",
    "# Run the agent\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9374cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_toolkits.llms import create_async_client\n",
    "\n",
    "client = create_async_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b46d7e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models.openai import OpenAIChatModel\n",
    "from pydantic_ai.providers.openai import OpenAIProvider\n",
    "model = OpenAIChatModel(\n",
    "    'gpt-4o', \n",
    "    provider=OpenAIProvider(openai_client=client)\n",
    ")\n",
    "agent = Agent(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e713256e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentRunResult(output=\"**The Eternal Sea**\\n\\nOh, endless sea, a boundless gray,  \\nYou shimmer soft at break of day.  \\nUpon your breath, the gulls alight,  \\nWhile waves cascade in foamy flight.  \\n\\nYou cradle secrets in your depths,  \\nOld whispered tales from each salt breath.  \\nOf ships long lost, of hearts once free,  \\nNow part of your eternity.  \\n\\nBeneath your surface, life abounds,  \\nA hidden realm where silence sounds.  \\nWith darting fish and coral's hue,  \\nThe ocean dreams in shades of blue.  \\n\\nYour tides may dance, your storms may roar,  \\nYet still you kiss the aching shore.  \\nA timeless rhythm, fierce and bold,  \\nThat soothes the heart and stirs the soul.  \\n\\nOh, mighty sea, both wild and vast,  \\nYou link the present to the past.  \\nAn endless muse, a mysteryâ€”  \\nForever shall I love the sea.  \")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run_sync(\"Write a poem about the sea.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3aa08a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:45:44.889 agent run\n",
      "13:45:44.890   chat gpt-4o\n",
      "city='Chicago' country='USA'\n",
      "RunUsage(input_tokens=58, output_tokens=19, details={'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, requests=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import logfire\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from pydantic_ai import Agent\n",
    "\n",
    "# 'if-token-present' means nothing will be sent (and the example will work) if you don't have logfire configured\n",
    "logfire.configure(send_to_logfire='if-token-present')\n",
    "logfire.instrument_pydantic_ai()\n",
    "\n",
    "\n",
    "class MyModel(BaseModel):\n",
    "    city: str\n",
    "    country: str\n",
    "\n",
    "agent = Agent(model, output_type=MyModel)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    result = agent.run_sync('The windy city in the US of A.')\n",
    "    print(result.output)\n",
    "    print(result.usage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bc14a74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "import uuid\n",
    "from typing import Optional\n",
    "\n",
    "class DirectedEdge(BaseModel):\n",
    "    \"\"\"An edge in a graph, if directed, goes from source_node to target_node, else it is undirected.\n",
    "    edge type defines a relationship between two nodes.\n",
    "    edge info is a dictionary that can contain any additional information about the edge.\n",
    "    \"\"\"\n",
    "    edge_id:Optional[str] = Field(\n",
    "        default_factory=lambda: str(uuid.uuid4())[:6], \n",
    "        description=\"The unique identifier of the edge, usually auto-generated\")\n",
    "    source_node_id: str = Field(..., description=\"The ID of the source node\")\n",
    "    target_node_id: str = Field(..., description=\"The ID of the target node\")   \n",
    "    edge_type:str = Field(None, description=\"The type of the edge, e.g., 'friendship', 'transaction', etc.\")\n",
    "    edge_attr:dict = Field(default_factory=dict, description=\"A dictionary of attributes for the edge\")\n",
    "    directed:bool = Field(default=True, description=\"Whether the edge is directed or not\")\n",
    "\n",
    "class Node(BaseModel):\n",
    "    \"\"\"Represents a node in a graph.\"\"\"\n",
    "    \n",
    "    node_id:Optional[str] = Field(\n",
    "        default_factory=lambda: str(uuid.uuid4())[:6], \n",
    "        description=\"The unique identifier of the node, usually auto-generated\")\n",
    "    node_name:str = Field(..., description=\"The name of the node\")\n",
    "    node_type:str = Field(..., description=\"The type of the node\")\n",
    "    node_attr:dict = Field(default_factory=dict, description=\"A dictionary of attributes for the node\")\n",
    "    \n",
    "    \n",
    "class Graph(BaseModel):\n",
    "    \"\"\"A simple graph structure with nodes and edges.\"\"\"\n",
    "    \n",
    "    nodes:list[Node] = Field(default_factory=list, description=\"A list of nodes in the graph\")\n",
    "    edges:list[DirectedEdge] = Field(default_factory=list, description=\"A list of edges in the graph\")\n",
    "    graph_desc:Optional[str] = Field(None, description=\"A description of the graph\")   \n",
    "    \n",
    "    def add_node(self, node:Node):\n",
    "        self.nodes.append(node)\n",
    "        \n",
    "    def add_edge(self, edge:DirectedEdge):\n",
    "        self.edges.append(edge) \n",
    "        \n",
    "    def one_step_upstream_nodes(self, node_id:str) -> list[Node]:\n",
    "        \"\"\"Get all upstream nodes of a given node.\"\"\"\n",
    "        upstream_node_ids = {edge.source_node_id \n",
    "                             for edge in self.edges \n",
    "                             if edge.target_node_id == node_id and edge.directed}\n",
    "        return [node for node in self.nodes if node.node_id in upstream_node_ids]\n",
    "    \n",
    "    def one_step_downstream_nodes(self, node_id:str) -> list[Node]:\n",
    "        \"\"\"Get all downstream nodes of a given node.\"\"\"\n",
    "        downstream_node_ids = {edge.target_node_id \n",
    "                               for edge in self.edges \n",
    "                               if edge.source_node_id == node_id and edge.directed}\n",
    "        return [node for node in self.nodes if node.node_id in downstream_node_ids]\n",
    "\n",
    "graph = Graph(graph_desc=\"A simple social graph\")\n",
    "\n",
    "def add_node(\n",
    "    node_name:str, \n",
    "    node_type:str, \n",
    "    node_attr:dict=None):\n",
    "    \"\"\"Add a node to the graph.\"\"\"\n",
    "    graph.add_node(\n",
    "        node_name=node_name, \n",
    "        node_type=node_type, \n",
    "        node_attr=node_attr or {})\n",
    "    \n",
    "def add_edge(\n",
    "    source_node_id:str, \n",
    "    target_node_id:str, \n",
    "    edge_type:str, \n",
    "    edge_attr:dict=None, \n",
    "    directed:bool=True):\n",
    "    \"\"\"Add an edge to the graph.\"\"\"\n",
    "    graph.add_edge(\n",
    "        source_node_id=source_node_id, \n",
    "        target_node_id=target_node_id, \n",
    "        edge_type=edge_type, \n",
    "        edge_attr=edge_attr or {}, \n",
    "        directed=directed\n",
    "    )\n",
    "   \n",
    "node1 = Node(node_name=\"Alice\", node_type=\"Person\", node_attr={\"age\": 30, \"city\": \"New York\"})\n",
    "node2 = Node(node_name=\"Bob\", node_type=\"Person\", node_attr={\"age\": 25, \"city\": \"San Francisco\"})\n",
    "edge = DirectedEdge(\n",
    "    source_node_id=node1.node_id, \n",
    "    target_node_id=node2.node_id, \n",
    "    edge_type=\"friendship\", \n",
    "    edge_attr={\"since\": 2020})\n",
    "\n",
    "graph.add_node(node1)\n",
    "graph.add_node(node2)\n",
    "graph.add_edge(edge)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
